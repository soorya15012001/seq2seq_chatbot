{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "chat.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flA_ybvSYnxT",
        "outputId": "f639b784-8f0c-415a-c0a4-9dc5cd57306e"
      },
      "source": [
        "import re\n",
        "\n",
        "\n",
        "lines = open('movie_lines.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n",
        "\n",
        "convers = open('movie_conversations.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n",
        "\n",
        "\n",
        "exchn = []\n",
        "for conver in convers:\n",
        "    exchn.append(conver.split(' +++$+++ ')[-1][1:-1].replace(\"'\", \" \").replace(\",\",\"\").split())\n",
        "\n",
        "diag = {}\n",
        "for line in lines:\n",
        "    diag[line.split(' +++$+++ ')[0]] = line.split(' +++$+++ ')[-1]\n",
        "\n",
        "## delete\n",
        "del(lines, convers, conver, line)\n",
        "\n",
        "questions = []\n",
        "answers = []\n",
        "\n",
        "for conver in exchn:\n",
        "    for i in range(len(conver) - 1):\n",
        "        questions.append(diag[conver[i]])\n",
        "        answers.append(diag[conver[i+1]])\n",
        "\n",
        "## delete\n",
        "del(diag, exchn, conver, i)\n",
        "\n",
        "\n",
        "###############################\n",
        "#        max_len = 13         #\n",
        "###############################\n",
        "\n",
        "sorted_ques = []\n",
        "sorted_ans = []\n",
        "for i in range(len(questions)):\n",
        "    if len(questions[i]) < 13:\n",
        "        sorted_ques.append(questions[i])\n",
        "        sorted_ans.append(answers[i])\n",
        "\n",
        "\n",
        "\n",
        "def clean_text(txt):\n",
        "    txt = txt.lower()\n",
        "    txt = re.sub(r\"i'm\", \"i am\", txt)\n",
        "    txt = re.sub(r\"he's\", \"he is\", txt)\n",
        "    txt = re.sub(r\"she's\", \"she is\", txt)\n",
        "    txt = re.sub(r\"that's\", \"that is\", txt)\n",
        "    txt = re.sub(r\"what's\", \"what is\", txt)\n",
        "    txt = re.sub(r\"where's\", \"where is\", txt)\n",
        "    txt = re.sub(r\"\\'ll\", \" will\", txt)\n",
        "    txt = re.sub(r\"\\'ve\", \" have\", txt)\n",
        "    txt = re.sub(r\"\\'re\", \" are\", txt)\n",
        "    txt = re.sub(r\"\\'d\", \" would\", txt)\n",
        "    txt = re.sub(r\"won't\", \"will not\", txt)\n",
        "    txt = re.sub(r\"can't\", \"can not\", txt)\n",
        "    txt = re.sub(r\"[^\\w\\s]\", \"\", txt)\n",
        "    return txt\n",
        "\n",
        "clean_ques = []\n",
        "clean_ans = []\n",
        "\n",
        "for line in sorted_ques:\n",
        "    clean_ques.append(clean_text(line))\n",
        "        \n",
        "for line in sorted_ans:\n",
        "    clean_ans.append(clean_text(line))\n",
        "\n",
        "\n",
        "\n",
        "## delete\n",
        "del(answers, questions, line)\n",
        "\n",
        "\n",
        "\n",
        "for i in range(len(clean_ans)):\n",
        "    clean_ans[i] = ' '.join(clean_ans[i].split()[:11])\n",
        "\n",
        "\n",
        "\n",
        "###############################\n",
        "#                             #\n",
        "###############################\n",
        "\n",
        "del(sorted_ans, sorted_ques)\n",
        "\n",
        "\n",
        "## trimming\n",
        "clean_ans=clean_ans[:30000]\n",
        "clean_ques=clean_ques[:30000]\n",
        "## delete\n",
        "\n",
        "\n",
        "###  count occurences ###\n",
        "word2count = {}\n",
        "\n",
        "for line in clean_ques:\n",
        "    for word in line.split():\n",
        "        if word not in word2count:\n",
        "            word2count[word] = 1\n",
        "        else:\n",
        "            word2count[word] += 1\n",
        "for line in clean_ans:\n",
        "    for word in line.split():\n",
        "        if word not in word2count:\n",
        "            word2count[word] = 1\n",
        "        else:\n",
        "            word2count[word] += 1\n",
        "\n",
        "## delete\n",
        "del(word, line)\n",
        "\n",
        "\n",
        "###  remove less frequent ###\n",
        "thresh = 5\n",
        "\n",
        "vocab = {}\n",
        "word_num = 0\n",
        "for word, count in word2count.items():\n",
        "    if count >= thresh:\n",
        "        vocab[word] = word_num\n",
        "        word_num += 1\n",
        "        \n",
        "## delete\n",
        "del(word2count, word, count, thresh)       \n",
        "del(word_num)        \n",
        "\n",
        "\n",
        "\n",
        "for i in range(len(clean_ans)):\n",
        "    clean_ans[i] = '<SOS> ' + clean_ans[i] + ' <EOS>'\n",
        "\n",
        "\n",
        "\n",
        "tokens = ['<PAD>', '<EOS>', '<OUT>', '<SOS>']\n",
        "x = len(vocab)\n",
        "for token in tokens:\n",
        "    vocab[token] = x\n",
        "    x += 1\n",
        "    \n",
        "    \n",
        "\n",
        "vocab['cameron'] = vocab['<PAD>']\n",
        "vocab['<PAD>'] = 0\n",
        "\n",
        "## delete\n",
        "del(token, tokens) \n",
        "del(x)\n",
        "\n",
        "### inv answers dict ###\n",
        "inv_vocab = {w:v for v, w in vocab.items()}\n",
        "\n",
        "\n",
        "\n",
        "## delete\n",
        "del(i)\n",
        "\n",
        "\n",
        "\n",
        "encoder_inp = []\n",
        "for line in clean_ques:\n",
        "    lst = []\n",
        "    for word in line.split():\n",
        "        if word not in vocab:\n",
        "            lst.append(vocab['<OUT>'])\n",
        "        else:\n",
        "            lst.append(vocab[word])\n",
        "        \n",
        "    encoder_inp.append(lst)\n",
        "\n",
        "decoder_inp = []\n",
        "for line in clean_ans:\n",
        "    lst = []\n",
        "    for word in line.split():\n",
        "        if word not in vocab:\n",
        "            lst.append(vocab['<OUT>'])\n",
        "        else:\n",
        "            lst.append(vocab[word])        \n",
        "    decoder_inp.append(lst)\n",
        "\n",
        "### delete\n",
        "del(clean_ans, clean_ques, line, lst, word)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "encoder_inp = pad_sequences(encoder_inp, 13, padding='post', truncating='post')\n",
        "decoder_inp = pad_sequences(decoder_inp, 13, padding='post', truncating='post')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "decoder_final_output = []\n",
        "for i in decoder_inp:\n",
        "    decoder_final_output.append(i[1:]) \n",
        "\n",
        "decoder_final_output = pad_sequences(decoder_final_output, 13, padding='post', truncating='post')\n",
        "\n",
        "\n",
        "del(i)\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "decoder_final_output = to_categorical(decoder_final_output, len(vocab))\n",
        "\n",
        "\n",
        "\n",
        "print(decoder_final_output.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30000, 13, 3027)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "M_zrNbblYnxb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3f23cc2-b431-4e51-eddb-01c74c8562ff"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Input\n",
        "\n",
        "\n",
        "enc_inp = Input(shape=(13, ))\n",
        "dec_inp = Input(shape=(13, ))\n",
        "\n",
        "\n",
        "VOCAB_SIZE = len(vocab)\n",
        "embed = Embedding(VOCAB_SIZE+1, output_dim=50, \n",
        "                  input_length=13,\n",
        "                  trainable=True                  \n",
        "                  )\n",
        "\n",
        "\n",
        "enc_embed = embed(enc_inp)\n",
        "enc_lstm = LSTM(400, return_sequences=True, return_state=True)\n",
        "enc_op, h, c = enc_lstm(enc_embed)\n",
        "enc_states = [h, c]\n",
        "\n",
        "\n",
        "\n",
        "dec_embed = embed(dec_inp)\n",
        "dec_lstm = LSTM(400, return_sequences=True, return_state=True)\n",
        "dec_op, _, _ = dec_lstm(dec_embed, initial_state=enc_states)\n",
        "\n",
        "dense = Dense(VOCAB_SIZE, activation='softmax')\n",
        "\n",
        "dense_op = dense(dec_op)\n",
        "\n",
        "model = Model([enc_inp, dec_inp], dense_op)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',metrics=['acc'],optimizer='adam')\n",
        "\n",
        "model.fit([encoder_inp, decoder_inp],decoder_final_output,epochs=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "938/938 [==============================] - 45s 13ms/step - loss: 3.5058 - acc: 0.4608\n",
            "Epoch 2/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 2.7749 - acc: 0.5290\n",
            "Epoch 3/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 2.6271 - acc: 0.5406\n",
            "Epoch 4/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 2.5423 - acc: 0.5457\n",
            "Epoch 5/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 2.4633 - acc: 0.5516\n",
            "Epoch 6/100\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 2.4261 - acc: 0.5526\n",
            "Epoch 7/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 2.3675 - acc: 0.5568\n",
            "Epoch 8/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 2.3303 - acc: 0.5574\n",
            "Epoch 9/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 2.2861 - acc: 0.5598\n",
            "Epoch 10/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 2.2515 - acc: 0.5601\n",
            "Epoch 11/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 2.1957 - acc: 0.5643\n",
            "Epoch 12/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 2.1602 - acc: 0.5659\n",
            "Epoch 13/100\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 2.1134 - acc: 0.5697\n",
            "Epoch 14/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 2.0799 - acc: 0.5716\n",
            "Epoch 15/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 2.0361 - acc: 0.5754\n",
            "Epoch 16/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.9925 - acc: 0.5811\n",
            "Epoch 17/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.9565 - acc: 0.5849\n",
            "Epoch 18/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.9133 - acc: 0.5909\n",
            "Epoch 19/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.8790 - acc: 0.5962\n",
            "Epoch 20/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.8410 - acc: 0.6012\n",
            "Epoch 21/100\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 1.8179 - acc: 0.6042\n",
            "Epoch 22/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.7772 - acc: 0.6108\n",
            "Epoch 23/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.7383 - acc: 0.6178\n",
            "Epoch 24/100\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 1.7050 - acc: 0.6226\n",
            "Epoch 25/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.6746 - acc: 0.6283\n",
            "Epoch 26/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.6435 - acc: 0.6345\n",
            "Epoch 27/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.6162 - acc: 0.6384\n",
            "Epoch 28/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.5938 - acc: 0.6425\n",
            "Epoch 29/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.5556 - acc: 0.6494\n",
            "Epoch 30/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.5317 - acc: 0.6545\n",
            "Epoch 31/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.5068 - acc: 0.6592\n",
            "Epoch 32/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.4696 - acc: 0.6668\n",
            "Epoch 33/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.4557 - acc: 0.6686\n",
            "Epoch 34/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.4180 - acc: 0.6784\n",
            "Epoch 35/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.3935 - acc: 0.6818\n",
            "Epoch 36/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.3740 - acc: 0.6869\n",
            "Epoch 37/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.3475 - acc: 0.6921\n",
            "Epoch 38/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.3258 - acc: 0.6976\n",
            "Epoch 39/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.2970 - acc: 0.7035\n",
            "Epoch 40/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.2755 - acc: 0.7081\n",
            "Epoch 41/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.2577 - acc: 0.7124\n",
            "Epoch 42/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.2307 - acc: 0.7182\n",
            "Epoch 43/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.2160 - acc: 0.7218\n",
            "Epoch 44/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.1920 - acc: 0.7270\n",
            "Epoch 45/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.1707 - acc: 0.7315\n",
            "Epoch 46/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.1475 - acc: 0.7362\n",
            "Epoch 47/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.1321 - acc: 0.7404\n",
            "Epoch 48/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.1111 - acc: 0.7450\n",
            "Epoch 49/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.0897 - acc: 0.7509\n",
            "Epoch 50/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.0769 - acc: 0.7532\n",
            "Epoch 51/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.0563 - acc: 0.7584\n",
            "Epoch 52/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.0363 - acc: 0.7632\n",
            "Epoch 53/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.0185 - acc: 0.7671\n",
            "Epoch 54/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.0002 - acc: 0.7720\n",
            "Epoch 55/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.9913 - acc: 0.7732\n",
            "Epoch 56/100\n",
            "938/938 [==============================] - 13s 13ms/step - loss: 0.9721 - acc: 0.7781\n",
            "Epoch 57/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.9634 - acc: 0.7802\n",
            "Epoch 58/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.9471 - acc: 0.7836\n",
            "Epoch 59/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.9357 - acc: 0.7866\n",
            "Epoch 60/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.9187 - acc: 0.7909\n",
            "Epoch 61/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.9027 - acc: 0.7949\n",
            "Epoch 62/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.8952 - acc: 0.7965\n",
            "Epoch 63/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.8818 - acc: 0.7998\n",
            "Epoch 64/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.8653 - acc: 0.8030\n",
            "Epoch 65/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.8562 - acc: 0.8057\n",
            "Epoch 66/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.8414 - acc: 0.8087\n",
            "Epoch 67/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.8296 - acc: 0.8122\n",
            "Epoch 68/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.8239 - acc: 0.8132\n",
            "Epoch 69/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.8070 - acc: 0.8170\n",
            "Epoch 70/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.8044 - acc: 0.8180\n",
            "Epoch 71/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.7925 - acc: 0.8203\n",
            "Epoch 72/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.7814 - acc: 0.8234\n",
            "Epoch 73/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.7762 - acc: 0.8241\n",
            "Epoch 74/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.7634 - acc: 0.8273\n",
            "Epoch 75/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.7514 - acc: 0.8306\n",
            "Epoch 76/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.7433 - acc: 0.8320\n",
            "Epoch 77/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.7393 - acc: 0.8332\n",
            "Epoch 78/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.7325 - acc: 0.8353\n",
            "Epoch 79/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.7216 - acc: 0.8364\n",
            "Epoch 80/100\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 0.7150 - acc: 0.8382\n",
            "Epoch 81/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.7050 - acc: 0.8409\n",
            "Epoch 82/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.6981 - acc: 0.8429\n",
            "Epoch 83/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.6932 - acc: 0.8427\n",
            "Epoch 84/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.6839 - acc: 0.8453\n",
            "Epoch 85/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.6831 - acc: 0.8454\n",
            "Epoch 86/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.6763 - acc: 0.8470\n",
            "Epoch 87/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.6647 - acc: 0.8500\n",
            "Epoch 88/100\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 0.6640 - acc: 0.8505\n",
            "Epoch 89/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.6553 - acc: 0.8521\n",
            "Epoch 90/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.6489 - acc: 0.8535\n",
            "Epoch 91/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.6433 - acc: 0.8542\n",
            "Epoch 92/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.6413 - acc: 0.8543\n",
            "Epoch 93/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.6309 - acc: 0.8576\n",
            "Epoch 94/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.6279 - acc: 0.8575\n",
            "Epoch 95/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.6229 - acc: 0.8593\n",
            "Epoch 96/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.6151 - acc: 0.8613\n",
            "Epoch 97/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.6124 - acc: 0.8604\n",
            "Epoch 98/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.6095 - acc: 0.8618\n",
            "Epoch 99/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.6000 - acc: 0.8638\n",
            "Epoch 100/100\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.5982 - acc: 0.8648\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd3a68a7ad0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ekFDm2T6Ynxc"
      },
      "source": [
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "\n",
        "enc_model = Model([enc_inp], enc_states)\n",
        "\n",
        "\n",
        "\n",
        "# decoder Model\n",
        "decoder_state_input_h = Input(shape=(400,))\n",
        "decoder_state_input_c = Input(shape=(400,))\n",
        "\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "\n",
        "decoder_outputs, state_h, state_c = dec_lstm(dec_embed , \n",
        "                                    initial_state=decoder_states_inputs)\n",
        "\n",
        "\n",
        "decoder_states = [state_h, state_c]\n",
        "  \n",
        "\n",
        "dec_model = Model([dec_inp]+ decoder_states_inputs,\n",
        "                                      [decoder_outputs]+ decoder_states)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaoVk-G4Ynxd",
        "outputId": "2f93d835-bb7e-4dd0-a97c-e1a1050c5923"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "print(\"##########################################\")\n",
        "print(\"#       start chatting ver. 1.0          #\")\n",
        "print(\"##########################################\")\n",
        "\n",
        "\n",
        "prepro1 = \"\"\n",
        "while prepro1 != 'q':\n",
        "    prepro1  = input(\"you : \")\n",
        "    ## prepro1 = \"Hello\"\n",
        "\n",
        "    prepro1 = clean_text(prepro1)\n",
        "    ## prepro1 = \"hello\"\n",
        "\n",
        "    prepro = [prepro1]\n",
        "    ## prepro1 = [\"hello\"]\n",
        "\n",
        "    txt = []\n",
        "    for x in prepro:\n",
        "        # x = \"hello\"\n",
        "        lst = []\n",
        "        for y in x.split():\n",
        "            ## y = \"hello\"\n",
        "            try:\n",
        "                lst.append(vocab[y])\n",
        "                ## vocab['hello'] = 454\n",
        "            except:\n",
        "                lst.append(vocab['<OUT>'])\n",
        "        txt.append(lst)\n",
        "\n",
        "    ## txt = [[454]]\n",
        "    txt = pad_sequences(txt, 13, padding='post', truncating='post')\n",
        "\n",
        "    ## txt = [[454,0,0,0,.........13]]\n",
        "\n",
        "    stat = enc_model.predict( txt )\n",
        "\n",
        "    empty_target_seq = np.zeros( ( 1 , 1) )\n",
        "     ##   empty_target_seq = [0]\n",
        "\n",
        "\n",
        "    empty_target_seq[0, 0] = vocab['<SOS>']\n",
        "    ##    empty_target_seq = [255]\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_translation = ''\n",
        "\n",
        "    while not stop_condition :\n",
        "\n",
        "        dec_outputs , h, c= dec_model.predict([ empty_target_seq] + stat )\n",
        "        decoder_concat_input = dense(dec_outputs)\n",
        "        ## decoder_concat_input = [0.1, 0.2, .4, .0, ...............]\n",
        "\n",
        "        sampled_word_index = np.argmax( decoder_concat_input[0, -1, :] )\n",
        "        ## sampled_word_index = [2]\n",
        "\n",
        "        sampled_word = inv_vocab[sampled_word_index] + ' '\n",
        "\n",
        "        ## inv_vocab[2] = 'hi'\n",
        "        ## sampled_word = 'hi '\n",
        "\n",
        "        if sampled_word != '<EOS> ':\n",
        "            decoded_translation += sampled_word  \n",
        "\n",
        "        if sampled_word == '<EOS> ' or len(decoded_translation.split()) > 13:\n",
        "            stop_condition = True \n",
        "\n",
        "        empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
        "        empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
        "        ## <SOS> - > hi\n",
        "        ## hi --> <EOS>\n",
        "        stat = [h, c]  \n",
        "\n",
        "    print(\"chatbot attention : \", decoded_translation )\n",
        "    print(\"==============================================\")  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "##########################################\n",
            "#       start chatting ver. 1.0          #\n",
            "##########################################\n",
            "you : hello\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 13) for input KerasTensor(type_spec=TensorSpec(shape=(None, 13), dtype=tf.float32, name='input_6'), name='input_6', description=\"created by layer 'input_6'\"), but it was called on an input with incompatible shape (None, 1).\n",
            "chatbot attention :  hello \n",
            "==============================================\n",
            "you : hi\n",
            "chatbot attention :  hi \n",
            "==============================================\n",
            "you : how are you ?\n",
            "chatbot attention :  fine fine \n",
            "==============================================\n",
            "you : what are you doing\n",
            "chatbot attention :  how could anyone do \n",
            "==============================================\n",
            "you : could you be good\n",
            "chatbot attention :  i am not going \n",
            "==============================================\n",
            "you : q\n",
            "chatbot attention :  <OUT> \n",
            "==============================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cgHu-PHUYnxe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}